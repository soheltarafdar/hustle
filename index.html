<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Copy Text Buttons</title>
    <style>
        button {
            margin: 5px;
        }

        body {
            background-color: #2B2730;
            /* background-image: url("https://raw.githubusercontent.com/hel0118/sukuna/main/jujutsu-kaisen-sukuna-uhdpaper.com-4K-7.3063.jpg"); */
            background-size: 100% auto;
            /* Center the background image */
            font-family: Arial, sans-serif;
            text-align: center; 
            transition: 1s ease-in-out;
        }

        /* @media only screen and (max-width: 600px) {

            /* Adjust properties for screens with a maximum width of 600px (adjust as needed
            body {
                /* background-image: url("https://raw.githubusercontent.com/hel0118/sukuna/main/real_esrgan_Zoro.jpg"); 
                background-size: 135%;
                /* Auto size for smaller screens 
                background-position: top;
                /* Center the background image, crop from top 
            }
        } 
        */


        button {
            color: #ccc;
            margin: 10px;
            padding: 10px;
            font-size: 16px;
            background-color: #dddddd00;
            /* Light gray button background */
            border: 1px solid #aaa;
            /* Dark gray border */
            cursor: pointer;
            transition: 500ms ease-in-out;
        }

        button:hover {
            color: darkslategrey;
            background-color: #ccc;
            /* Slightly darker background on hover */
        }
    </style>
</head>

<body>

    <button onclick="copyText(text1)">Linear Neural Network(Binary and Bipolar sigmoidal)</button>
    <button onclick="copyText(text2)">SVM</button>
    <button onclick="copyText(text3)">Decision Tree</button>
    <button onclick="copyText(text4)">KNN-K Nearest Neighbour</button>
    <button onclick="copyText(text5)">KMeans</button>
    <button onclick="copyText(GaussianNB)"> Naive Bayes</button>
    <button onclick="copyText(text9)">McCulloch Pitts</button>
    <p id="copiedMsg"></p>
    <h6>If You are using jupyter online and getting "PyodideFuture" Error use await keyword before input e.g float(await input("Enter Number")) and make sure that per cell has a single input method</h6>
    <script>
var text1 = `
#LNN
# simple neural network 
x=float(input("Enter the value x:"))
w=float(input("Enter the value w:"))
b=float(input("Enter the value b:"))
net=int(w*x+b)
if(net<0):
    out=0
elif((net>=0)&(net<=1)):
    out=net
else:
    out=1
print("net:",net)
print("output:",out)

#multi
# number of elements as input
n= int(input("Enter number of elements:"))
print("enter the inputs")
inputs=[]
for i in range(0,n):
    ele= float(input())
    inputs.append(ele)
print(inputs)
print("Enter the weights")
weights=[]
for i in range(0,n):
    ele = float(input())
    weights.append(ele)
print(weights)
print("The net input can be calculated as Yin=x1w1+x2w2+x3w3")
Yin=[]
for i in range(0,n):
    Yin.append(inputs[i]*weights[i])
print(round(sum(Yin),3))`;

var text2 = `
#SVM
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.svm import SVC,LinearSVC
import plotly.express as pl
from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict
from sklearn.metrics import confusion_matrix
pd.set_option('display.max_rows',1000)
pd.set_option('display.max_columns',1000)
pd.set_option('display.width',1000)
data = pd.read_csv('diabetes.csv')
print(data.head())
print(data.tail())
print(data.shape)
data.describe()
x=data.drop('Outcome',axis=1)
y = data["Outcome"] #will predict outcome (diabetes)
x_train = x.iloc[:600]
x_test = x.iloc[600:]
y_train = y[:600]
y_test = y[600:]
print("x_train Shape: ", x_train.shape)
print("x_test Shape: ", x_test.shape)
print("y_train Shape: ", y_train.shape)
print("y_test Shape: ", y_test.shape)
support_vector_classifier=SVC(kernel="linear").fit(x_train,y_train)
print(support_vector_classifier)
print(support_vector_classifier.C)
print(support_vector_classifier)
y_pred=support_vector_classifier.predict(x_test)
cm=confusion_matrix(y_test,y_pred)
print("confusion matrix",cm)`

var text3 = `
#Dtree
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn import tree

dataTable = pd.read_csv("PlayTennis.csv")
dataTable

dataTable.shape

dataTable.describe()

dataTable.dtypes

dataTable.head(5)

dataTable.tail(5)

dataTable.columns

Le = LabelEncoder()
dataTable['Outlook'] = Le.fit_transform(dataTable ['Outlook'])
dataTable['Temperature'] = Le.fit_transform (dataTable ['Temperature'])
dataTable['Humidity'] = Le.fit_transform(dataTable['Humidity'])
dataTable['Wind'] = Le.fit_transform (dataTable ['Wind'])
dataTable['Play Tennis'] = Le.fit_transform (dataTable['Play Tennis'])
dataTable

y = dataTable['Play Tennis']
x = dataTable.drop(['Play Tennis'], axis=1)
x.dtypes

clf = tree.DecisionTreeClassifier(criterion = 'entropy')
clf = clf.fit(x,y)
tree.plot_tree(clf)`;

var text4 = `
#KNN
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
df= pd.read_csv("diabetes.csv")
print(df.head())
print(df.shape)
print(df.dtypes)
x= df.drop('Outcome', axis=1).values
y= df['Outcome'].values
print(df)
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.4,random_state=42)
from sklearn.neighbors import KNeighborsClassifier
neighbors = np.arange(1,9)

train_accuracy = np.empty(len(neighbors))

test_accuracy = np.empty(len(neighbors))

for i,k in enumerate(neighbors):
    #Setup a knn classifier with k neighbors
    knn = KNeighborsClassifier(n_neighbors=k)
    #Fit the model
    knn.fit(x_train, y_train)
    #compute accuracy on the training set
    train_accuracy[i] = knn.score (x_train, y_train)
    #Compute accuracy on the test set
    test_accuracy[i] = knn.score (x_test, y_test)
plt.title('k-NN Varying number of neighbors')
plt.plot(neighbors, test_accuracy, label="Testing Accuracy")
plt.plot(neighbors, train_accuracy, label='Training accuracy')
plt.legend()
plt.xlabel('Number of neighbors')
plt.ylabel('Accuracy')
plt.show()
knn = KNeighborsClassifier (n_neighbors=7)
print(knn.fit(x_train,y_train))
print(knn.score(x_test,y_test))
from sklearn.metrics import confusion_matrix
y_pred = knn.predict(x_test)
confusion_matrix(y_test,y_pred)
from sklearn.metrics import classification_report
print(classification_report (y_test,y_pred))
y_pred_proba = knn.predict_proba (x_test)[:,1]
from sklearn.metrics import roc_curve
fpr, tpr, thresholds=roc_curve (y_test, y_pred_proba)
plt.plot([0,1],[0,1], 'k--')
plt.plot(fpr, tpr, label='Knn', color= 'darkred')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.title('Knn(n_neighbors=7) ROC curve')
plt.show()
from sklearn.metrics import roc_auc_score
roc_auc_score
print((y_test,y_pred_proba))
from sklearn.model_selection import GridSearchCV
param_grid = {'n_neighbors': np.arange(1,50)}
knn = KNeighborsClassifier()
knn_cv= GridSearchCV (knn, param_grid,cv=5)
knn_cv.fit(x,y)
print(knn_cv.best_score_)
print(knn_cv.best_params_)`;

var text5 = `
#KMEAN
import pandas as pd
import warnings
warnings.filterwarnings("ignore")
homedata=pd.read_csv("./housing.csv", usecols=['longitude', 'latitude', 'median_house_value'])
print(homedata.head())
import seaborn as sns
sns.scatterplot(data=homedata, x='longitude', y='latitude', hue='median_house_value')
from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest =train_test_split(homedata[['longitude','latitude']],homedata[['median_house_value']], test_size=0.33, random_state=42)
print('xtrain',xtrain,'xtest',xtest,'ytrain',ytrain,'ytest',ytest)
from sklearn import preprocessing
xtrainnorm= preprocessing.normalize(xtrain)
ytrainnorm= preprocessing.normalize(ytrain)
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=5, random_state=41)
print(kmeans.fit(xtrainnorm))
sns.scatterplot(xtrain, x='longitude', y='latitude', hue=kmeans.labels_)
sns.boxplot(x= kmeans.labels_,y=ytrain['median_house_value'])
from sklearn.metrics import silhouette_score
print(silhouette_score(xtrainnorm, kmeans.labels_, metric='euclidean'))
K = range(2,8)
fits = []
score = []

for k in K:
    #train the model for current value of k on training data
    model = KMeans(n_clusters = k, random_state = 0).fit(xtrainnorm)

    #append the model to fits
    fits.append(model)

    #append the silhouette score to scores
    score.append(silhouette_score(xtrainnorm, model.labels_, metric='euclidean'))
sns.scatterplot(data = xtrain, x='longitude',y='latitude', hue = fits[5].labels_)
sns.lineplot(x=K,y=score)
`;

var GaussianNB = `
#Naive Bayes GaussianNB, MultinomialNB ,CategoricalNB
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

from sklearn.naive_bayes import MultinomialNB ,CategoricalNB

from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,precision_score,recall_score,f1_score
#importing data set 
iris= pd.read_csv('Iris.csv')
print(iris)
#print top 5 
print(iris.head(5))
#print last 5
print(iris.tail(5))
#describe some common statistical value about data set
print(iris.describe())
# print no. of  rows and columns
print(iris.shape)
#basics information about dataset
print(iris.info())
#datatype of each columns
print(iris.dtypes)
#printing just columns names
print(iris.columns)
# Selecting features from which we're  going to train model 

#Selecting all values of  'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'(Prediction Input)

X = iris.iloc[:, [1, 2, 3,4]].values

#Selecting all values of Species (Prediction Output)
Y = iris.iloc[:, 5].values
#from sklearn import datasets
#X = iris.data
#y = iris.target
#data,target = datasets.load_iris(return_X_y=True)

#Using train_test_split to split the whole data into training and testing data
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

#Gaussain naive Bayes 

print("***For Gaussain Naive bayes classification***** \n")

#GNBclf =  Gaussian naive bayes classification

#Storing model in a variable
GNBclf =GaussianNB()

#Training model with training data
GNBclf.fit(X_train, y_train)

#Predicting model 
y_pred = GNBclf.predict(X_test)


#predicting  the species with custom input 
out = GNBclf.predict([[5.9,3.0,5.1,1.8]])
print("++++>>>Predicted species:",out)
# Had to set pos_label='positive',average='micro'
#Print Confusion Matrix
print("Confusion Matrix \n",confusion_matrix(y_test, y_pred))
#Print Accuracy
print("Accuracy : \n", accuracy_score(y_test, y_pred))
#Generating the reports
print("Classification report: \n:",classification_report(y_test,y_pred))

#Multinomial  naive Bayes 

print("***For Multinomial naive bayes classification***** \n")

#MNBclf =  Multinomial naive bayes classification
MNBclf =MultinomialNB()
MNBclf.fit(X_train, y_train)
y_pred = MNBclf.predict(X_test)

#predicting  the species with custom input 
out = MNBclf.predict([[5.9,3.0,5.1,1.8]])
print("++++>>>Predicted species:",out)
#Print Confusion Matrix
print("Confusion Matrix \n",confusion_matrix(y_test, y_pred))
#Print Accuracy
print("Accuracy : \n", accuracy_score(y_test, y_pred))
#Generating the reports
print("Classification report:: \n:",classification_report(y_test,y_pred))

#Categorical  naive Bayes 

print("***For Categorical naive bayes classification***** \n")

#CNBclf =  Categorical naive bayes classification
CNBclf =CategoricalNB()
CNBclf.fit(X_train, y_train)
y_pred = CNBclf.predict(X_test)


#predicting  the species with custom input 
out = CNBclf.predict([[5.9,3.0,5.1,1.8]])
print("++++>>>Predicted species:",out)
#Print Confusion Matrix
print("Confusion Matrix \n",confusion_matrix(y_test, y_pred))
#Generating the reports
print("Classification report: \n:",classification_report(y_test,y_pred))
#Print Accuracy
print("Accuracy : \n", accuracy_score(y_test, y_pred))`;


var text9 = `
#McllouPits
# import numpy
# enter the no of values
num_ip = int(input("Enter the number of inputs:"))
# set the weights with value 1
w1= 1
w2= 1
print("For the",num_ip,"inputs calculate the net input using yin= x1w1 + x2w2")
x1= []
x2= []
for j in range(0,num_ip):
    e1e1 = int(input("x1 = "))
    e1e2 = int(input("x2 = "))
    x1.append(e1e1)
    x2.append(e1e2)
print("x1 = ",x1)
print("x2 = ",x2)
n = x1 * w1
m = x2 * w2
Yin = []
for i in range(0,num_ip):
    Yin.append(n[i] + m[i])
print("Yin =", Yin) 
Yin = []
for i in range(0,num_ip):
    Yin.append(n[i] - m[i])
print("After assuming one weight as excitatory and the other as inhibitory Yin=", Yin)
#from the calculated net inputs, now it is possible yo fire the neuron for input(1,-1)
# only by fixing a threshold of 1, i.e., 0 > 1 for Y unit
# Thus, w1 = 1, w2= -1, 0>=1
Y=[]
for i in range(0,num_ip):
    if(Yin[i]>=1):
        ele=1
        Y.append(ele)
    if(Yin[i]<1):
        ele=0
        Y.append(ele)
print("Y=",Y)
`;
        function copyText(text) {
            navigator.clipboard.writeText(text).then(function () {
                document.getElementById('copiedMsg').innerHTML = "Text Copied"
            }).catch(function (err) {
                console.error('Unable to copy text', err);
            });
        }
    </script>

</body>

  </html>
